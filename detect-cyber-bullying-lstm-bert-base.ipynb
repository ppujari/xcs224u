{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57dd2c1e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-13T16:49:54.572022Z",
     "iopub.status.busy": "2024-10-13T16:49:54.571590Z",
     "iopub.status.idle": "2024-10-13T16:49:54.605096Z",
     "shell.execute_reply": "2024-10-13T16:49:54.603569Z",
     "shell.execute_reply.started": "2024-10-13T16:49:54.571980Z"
    },
    "papermill": {
     "duration": 0.008685,
     "end_time": "2024-10-19T03:17:51.561586",
     "exception": false,
     "start_time": "2024-10-19T03:17:51.552901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentiment Network with PyTorch\n",
    "\n",
    "Below is where you'll define the network.\n",
    "\n",
    "<img src=\"assets/network_diagram.png\" width=40%>\n",
    "\n",
    "The layers are as follows:\n",
    "1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n",
    "2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n",
    "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n",
    "\n",
    "### The Embedding Layer\n",
    "\n",
    "We need to add an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) because there are 74000+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n",
    "\n",
    "\n",
    "### The LSTM Layer(s)\n",
    "\n",
    "We'll create an [LSTM](https://pytorch.org/docs/stable/nn.html#lstm) to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter.\n",
    "\n",
    "Most of the time, you're network will have better performance with more layers; between 2-3. Adding more layers allows the network to learn really complex relationships. \n",
    "\n",
    "> **Here implement:** Complete the `__init__`, `forward`, and `init_hidden` functions for the SentimentRNN model class.\n",
    "\n",
    "Note: `init_hidden` should initialize the hidden and cell state of an lstm layer to all zeros, and move those state to GPU, if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9aa9b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:17:51.579934Z",
     "iopub.status.busy": "2024-10-19T03:17:51.579485Z",
     "iopub.status.idle": "2024-10-19T03:18:01.071949Z",
     "shell.execute_reply": "2024-10-19T03:18:01.070777Z"
    },
    "papermill": {
     "duration": 9.504818,
     "end_time": "2024-10-19T03:18:01.074839",
     "exception": false,
     "start_time": "2024-10-19T03:17:51.570021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.metrics import fbeta_score\n",
    "from IPython.display import Image\n",
    "from transformers import BertTokenizer, BertModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec2d9136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.092648Z",
     "iopub.status.busy": "2024-10-19T03:18:01.092022Z",
     "iopub.status.idle": "2024-10-19T03:18:01.098875Z",
     "shell.execute_reply": "2024-10-19T03:18:01.097665Z"
    },
    "papermill": {
     "duration": 0.018417,
     "end_time": "2024-10-19T03:18:01.101273",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.082856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbcd4677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.119027Z",
     "iopub.status.busy": "2024-10-19T03:18:01.118605Z",
     "iopub.status.idle": "2024-10-19T03:18:01.260438Z",
     "shell.execute_reply": "2024-10-19T03:18:01.259234Z"
    },
    "papermill": {
     "duration": 0.153595,
     "end_time": "2024-10-19T03:18:01.263101",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.109506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/formspring-csv/formspring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f219c75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.281997Z",
     "iopub.status.busy": "2024-10-19T03:18:01.281557Z",
     "iopub.status.idle": "2024-10-19T03:18:01.300165Z",
     "shell.execute_reply": "2024-10-19T03:18:01.298721Z"
    },
    "papermill": {
     "duration": 0.030639,
     "end_time": "2024-10-19T03:18:01.302869",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.272230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(['post', 'asker', 'bully1', 'bully2', 'bully3'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b49717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.320509Z",
     "iopub.status.busy": "2024-10-19T03:18:01.320074Z",
     "iopub.status.idle": "2024-10-19T03:18:01.325494Z",
     "shell.execute_reply": "2024-10-19T03:18:01.324364Z"
    },
    "papermill": {
     "duration": 0.016804,
     "end_time": "2024-10-19T03:18:01.327664",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.310860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_ans_columns(value):\n",
    "    v = ['No','nan']\n",
    "    if value in v:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067452b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.345001Z",
     "iopub.status.busy": "2024-10-19T03:18:01.344553Z",
     "iopub.status.idle": "2024-10-19T03:18:01.391297Z",
     "shell.execute_reply": "2024-10-19T03:18:01.390192Z"
    },
    "papermill": {
     "duration": 0.058188,
     "end_time": "2024-10-19T03:18:01.393723",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.335535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>ques</th>\n",
       "      <th>ans</th>\n",
       "      <th>ans1</th>\n",
       "      <th>severity1</th>\n",
       "      <th>ans2</th>\n",
       "      <th>severity2</th>\n",
       "      <th>ans3</th>\n",
       "      <th>severity3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>zooshay</td>\n",
       "      <td>or the annoying back driver?</td>\n",
       "      <td>nope not me hate the back i always say i get ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aguitarplayer94</td>\n",
       "      <td>what&amp;#039;s your favorite song? :D&lt;br&gt;</td>\n",
       "      <td>I like too many songs to have a favorite</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>freshswagg21</td>\n",
       "      <td>fagg</td>\n",
       "      <td>hahahahaha you the fagg buddy lol:)</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>outlaw9000</td>\n",
       "      <td>Ahh i see. tut tut :P bit naughty eh :P</td>\n",
       "      <td>that's why I am an Outlaw ! ! LOL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>kellyblake1</td>\n",
       "      <td>What is your saddest memory?</td>\n",
       "      <td>Loosing the people that I love... I will neve...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>teaachgee</td>\n",
       "      <td>What&amp;#039;s one thing you hate the feeling of?</td>\n",
       "      <td>being lied to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12618</th>\n",
       "      <td>outlaw9000</td>\n",
       "      <td>what&amp;#039;s your biggest pet peeve?</td>\n",
       "      <td>sloopy people</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7135</th>\n",
       "      <td>zooshay</td>\n",
       "      <td>when do u feel most yourself? online? in persom?</td>\n",
       "      <td>Both</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>dearalexiis</td>\n",
       "      <td>Mall or Park?</td>\n",
       "      <td>Mall i guesss</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>zooshay</td>\n",
       "      <td>lol u have a stalker O_O</td>\n",
       "      <td>i doo i actually have many :) can u take sum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                userid                                              ques  \\\n",
       "6571           zooshay                      or the annoying back driver?   \n",
       "0      aguitarplayer94            what&#039;s your favorite song? :D<br>   \n",
       "4244      freshswagg21                                              fagg   \n",
       "10957       outlaw9000           Ahh i see. tut tut :P bit naughty eh :P   \n",
       "9799       kellyblake1                      What is your saddest memory?   \n",
       "2226         teaachgee    What&#039;s one thing you hate the feeling of?   \n",
       "12618       outlaw9000               what&#039;s your biggest pet peeve?   \n",
       "7135           zooshay  when do u feel most yourself? online? in persom?   \n",
       "2680       dearalexiis                                     Mall or Park?   \n",
       "6377           zooshay                          lol u have a stalker O_O   \n",
       "\n",
       "                                                     ans  ans1 severity1  \\\n",
       "6571    nope not me hate the back i always say i get ...     0         0   \n",
       "0               I like too many songs to have a favorite     0         0   \n",
       "4244                 hahahahaha you the fagg buddy lol:)     1         5   \n",
       "10957                  that's why I am an Outlaw ! ! LOL     0         0   \n",
       "9799    Loosing the people that I love... I will neve...     0         0   \n",
       "2226                                       being lied to     0         0   \n",
       "12618                                      sloopy people     0         0   \n",
       "7135                                                Both     0         0   \n",
       "2680                                       Mall i guesss     0         0   \n",
       "6377    i doo i actually have many :) can u take sum ...     0         0   \n",
       "\n",
       "       ans2 severity2  ans3 severity3  \n",
       "6571      0         0     0         0  \n",
       "0         0         0     0         0  \n",
       "4244      1         4     1       NaN  \n",
       "10957     0         0     0         0  \n",
       "9799      0         0     0         0  \n",
       "2226      0         0     0         0  \n",
       "12618     0         0     0         0  \n",
       "7135      0         0     0         0  \n",
       "2680      0         0     0         0  \n",
       "6377      1         3     0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['ans1', 'ans2', 'ans3']:\n",
    "    df[col] = df[col].apply(impute_ans_columns)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56bdf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.412612Z",
     "iopub.status.busy": "2024-10-19T03:18:01.411466Z",
     "iopub.status.idle": "2024-10-19T03:18:01.418426Z",
     "shell.execute_reply": "2024-10-19T03:18:01.417270Z"
    },
    "papermill": {
     "duration": 0.018939,
     "end_time": "2024-10-19T03:18:01.421029",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.402090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_severity_columns(value):\n",
    "    '''Value will be a string. We need to convert it to int'''\n",
    "    v = ['nan', 'None', '0']\n",
    "    if value in v:\n",
    "        return 0\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError as e:\n",
    "        #print(value)\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9cac76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.440434Z",
     "iopub.status.busy": "2024-10-19T03:18:01.439273Z",
     "iopub.status.idle": "2024-10-19T03:18:01.467659Z",
     "shell.execute_reply": "2024-10-19T03:18:01.466179Z"
    },
    "papermill": {
     "duration": 0.040574,
     "end_time": "2024-10-19T03:18:01.470311",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.429737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in ['severity1', 'severity2', 'severity3']:\n",
    "    df[col] = df[col].apply(impute_severity_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb6a81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.491332Z",
     "iopub.status.busy": "2024-10-19T03:18:01.490293Z",
     "iopub.status.idle": "2024-10-19T03:18:01.502042Z",
     "shell.execute_reply": "2024-10-19T03:18:01.500840Z"
    },
    "papermill": {
     "duration": 0.02482,
     "end_time": "2024-10-19T03:18:01.504683",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.479863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['IsBully'] = (\n",
    "    (df.ans1 * df.severity1 + df.ans2 * df.severity2 + df.ans3 * df.severity3) / 30) >= 0.0333\n",
    "\n",
    "# Remove uneccessary columns\n",
    "df_2 = df.drop(['userid','ans1', 'severity1','ans2','severity2','ans3','severity3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ad0b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.523205Z",
     "iopub.status.busy": "2024-10-19T03:18:01.522660Z",
     "iopub.status.idle": "2024-10-19T03:18:01.535828Z",
     "shell.execute_reply": "2024-10-19T03:18:01.534513Z"
    },
    "papermill": {
     "duration": 0.025276,
     "end_time": "2024-10-19T03:18:01.538336",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.513060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques</th>\n",
       "      <th>ans</th>\n",
       "      <th>IsBully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9934</th>\n",
       "      <td>Who&amp;#039;s the most underrated actor?</td>\n",
       "      <td>Without doubt  Lily Loveless</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>If you saw a serious crime take place and if y...</td>\n",
       "      <td>YES :)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>but never dtf</td>\n",
       "      <td>Neverz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>I LiKe U G stRiNg</td>\n",
       "      <td>cool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>0</td>\n",
       "      <td>b****</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>what&amp;#039;s the last thing you said to your si...</td>\n",
       "      <td>I love you...? haha</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7963</th>\n",
       "      <td>Oh never mind  good luck child.</td>\n",
       "      <td>Who needs luck?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6784</th>\n",
       "      <td>waht are some stores you go to?</td>\n",
       "      <td>supre  myer dereon ahh i cant really think of...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Do you believe in life after death?</td>\n",
       "      <td>Yes of course i do... Its called Eternity wit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>Hot or Cold?</td>\n",
       "      <td>Dependss .</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ques  \\\n",
       "9934              Who&#039;s the most underrated actor?   \n",
       "1676  If you saw a serious crime take place and if y...   \n",
       "7637                                      but never dtf   \n",
       "6008                                  I LiKe U G stRiNg   \n",
       "4973                                                  0   \n",
       "2243  what&#039;s the last thing you said to your si...   \n",
       "7963                    Oh never mind  good luck child.   \n",
       "6784                    waht are some stores you go to?   \n",
       "22                  Do you believe in life after death?   \n",
       "2645                                       Hot or Cold?   \n",
       "\n",
       "                                                    ans  IsBully  \n",
       "9934                       Without doubt  Lily Loveless    False  \n",
       "1676                                             YES :)    False  \n",
       "7637                                             Neverz    False  \n",
       "6008                                               cool    False  \n",
       "4973                                              b****     True  \n",
       "2243                                I love you...? haha    False  \n",
       "7963                                    Who needs luck?    False  \n",
       "6784   supre  myer dereon ahh i cant really think of...    False  \n",
       "22     Yes of course i do... Its called Eternity wit...    False  \n",
       "2645                                         Dependss .    False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c898239c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.557612Z",
     "iopub.status.busy": "2024-10-19T03:18:01.556689Z",
     "iopub.status.idle": "2024-10-19T03:18:01.593677Z",
     "shell.execute_reply": "2024-10-19T03:18:01.592333Z"
    },
    "papermill": {
     "duration": 0.04923,
     "end_time": "2024-10-19T03:18:01.596091",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.546861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in ['ques', 'ans']:\n",
    "    df_2[col] = df_2[col].str.replace(\"&#039;\", \"'\") # Put back the apostrophe\n",
    "\n",
    "    df_2[col] = df_2[col].str.replace(\"<br>\", \"\") \n",
    "    df_2[col] = df_2[col].str.replace(\"&quot;\", \"\") \n",
    "    #df_2[col] = df_2[col].str.replace(\"<3\", \"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5aa461a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.615584Z",
     "iopub.status.busy": "2024-10-19T03:18:01.614563Z",
     "iopub.status.idle": "2024-10-19T03:18:01.624574Z",
     "shell.execute_reply": "2024-10-19T03:18:01.623237Z"
    },
    "papermill": {
     "duration": 0.022511,
     "end_time": "2024-10-19T03:18:01.627203",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.604692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e961107d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.645968Z",
     "iopub.status.busy": "2024-10-19T03:18:01.645544Z",
     "iopub.status.idle": "2024-10-19T03:18:01.656446Z",
     "shell.execute_reply": "2024-10-19T03:18:01.655403Z"
    },
    "papermill": {
     "duration": 0.022817,
     "end_time": "2024-10-19T03:18:01.658587",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.635770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques</th>\n",
       "      <th>ans</th>\n",
       "      <th>IsBully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what's your favorite song? :D</td>\n",
       "      <td>I like too many songs to have a favorite</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;3</td>\n",
       "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey angel  you duh sexy</td>\n",
       "      <td>Really?!?! Thanks?! haha</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(:</td>\n",
       "      <td>;(</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>******************MEOWWW*************************</td>\n",
       "      <td>*RAWR*?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ques  \\\n",
       "0                      what's your favorite song? :D   \n",
       "1                                                 <3   \n",
       "2                            hey angel  you duh sexy   \n",
       "3                                                 (:   \n",
       "4  ******************MEOWWW*************************   \n",
       "\n",
       "                                         ans  IsBully  \n",
       "0   I like too many songs to have a favorite    False  \n",
       "1                         </3 ? haha jk! <33    False  \n",
       "2                   Really?!?! Thanks?! haha    False  \n",
       "3                                         ;(    False  \n",
       "4                                    *RAWR*?    False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84fb1476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.678535Z",
     "iopub.status.busy": "2024-10-19T03:18:01.677512Z",
     "iopub.status.idle": "2024-10-19T03:18:01.694672Z",
     "shell.execute_reply": "2024-10-19T03:18:01.693579Z"
    },
    "papermill": {
     "duration": 0.029998,
     "end_time": "2024-10-19T03:18:01.697410",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.667412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2['ques_ans'] = df_2['ques'] + ' ' + df_2['ans'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7630b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.716403Z",
     "iopub.status.busy": "2024-10-19T03:18:01.715990Z",
     "iopub.status.idle": "2024-10-19T03:18:01.728753Z",
     "shell.execute_reply": "2024-10-19T03:18:01.727615Z"
    },
    "papermill": {
     "duration": 0.024792,
     "end_time": "2024-10-19T03:18:01.730955",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.706163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques</th>\n",
       "      <th>ans</th>\n",
       "      <th>IsBully</th>\n",
       "      <th>ques_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what's your favorite song? :D</td>\n",
       "      <td>I like too many songs to have a favorite</td>\n",
       "      <td>False</td>\n",
       "      <td>what's your favorite song? :D  I like too many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;3</td>\n",
       "      <td>&lt;/3 ? haha jk! &lt;33</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;3  &lt;/3 ? haha jk! &lt;33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey angel  you duh sexy</td>\n",
       "      <td>Really?!?! Thanks?! haha</td>\n",
       "      <td>False</td>\n",
       "      <td>hey angel  you duh sexy  Really?!?! Thanks?! haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(:</td>\n",
       "      <td>;(</td>\n",
       "      <td>False</td>\n",
       "      <td>(:  ;(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>******************MEOWWW*************************</td>\n",
       "      <td>*RAWR*?</td>\n",
       "      <td>False</td>\n",
       "      <td>******************MEOWWW**********************...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ques  \\\n",
       "0                      what's your favorite song? :D   \n",
       "1                                                 <3   \n",
       "2                            hey angel  you duh sexy   \n",
       "3                                                 (:   \n",
       "4  ******************MEOWWW*************************   \n",
       "\n",
       "                                         ans  IsBully  \\\n",
       "0   I like too many songs to have a favorite    False   \n",
       "1                         </3 ? haha jk! <33    False   \n",
       "2                   Really?!?! Thanks?! haha    False   \n",
       "3                                         ;(    False   \n",
       "4                                    *RAWR*?    False   \n",
       "\n",
       "                                            ques_ans  \n",
       "0  what's your favorite song? :D  I like too many...  \n",
       "1                             <3  </3 ? haha jk! <33  \n",
       "2  hey angel  you duh sexy  Really?!?! Thanks?! haha  \n",
       "3                                             (:  ;(  \n",
       "4  ******************MEOWWW**********************...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b2aa0fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.751106Z",
     "iopub.status.busy": "2024-10-19T03:18:01.750055Z",
     "iopub.status.idle": "2024-10-19T03:18:01.805667Z",
     "shell.execute_reply": "2024-10-19T03:18:01.804250Z"
    },
    "papermill": {
     "duration": 0.068739,
     "end_time": "2024-10-19T03:18:01.808591",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.739852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/2035247237.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n",
      "/tmp/ipykernel_17/2035247237.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)\n"
     ]
    }
   ],
   "source": [
    "df_2.drop(['ques','ans'], axis=1)\n",
    "columns = ['ques_ans','IsBully']\n",
    "df2_ordered = df_2[columns]\n",
    "df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n",
    "# Remove punctuation using regex\n",
    "df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d469b018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.828818Z",
     "iopub.status.busy": "2024-10-19T03:18:01.828364Z",
     "iopub.status.idle": "2024-10-19T03:18:01.850197Z",
     "shell.execute_reply": "2024-10-19T03:18:01.849152Z"
    },
    "papermill": {
     "duration": 0.034883,
     "end_time": "2024-10-19T03:18:01.852572",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.817689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_ans</th>\n",
       "      <th>IsBully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whats your favorite song d  i like too many so...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3  3  haha jk 33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey angel  you duh sexy  really thanks haha</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meowww  rawr</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>any makeup tips i suck at doing my makeup lol ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ques_ans  IsBully\n",
       "0  whats your favorite song d  i like too many so...    False\n",
       "1                                   3  3  haha jk 33    False\n",
       "2        hey angel  you duh sexy  really thanks haha    False\n",
       "4                                       meowww  rawr    False\n",
       "5  any makeup tips i suck at doing my makeup lol ...    False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_ordered = df2_ordered[df2_ordered['ques_ans'].notna()]  # Remove NaN values\n",
    "df2_ordered = df2_ordered[df2_ordered['ques_ans'].str.strip() != '']  # Remove empty strings\n",
    "df2_ordered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d557bfba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.873811Z",
     "iopub.status.busy": "2024-10-19T03:18:01.873366Z",
     "iopub.status.idle": "2024-10-19T03:18:01.879076Z",
     "shell.execute_reply": "2024-10-19T03:18:01.878033Z"
    },
    "papermill": {
     "duration": 0.019144,
     "end_time": "2024-10-19T03:18:01.881285",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.862141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df2_ordered['ques_ans'].values\n",
    "y = df2_ordered['IsBully'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0947fb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:01.901582Z",
     "iopub.status.busy": "2024-10-19T03:18:01.901088Z",
     "iopub.status.idle": "2024-10-19T03:18:16.512715Z",
     "shell.execute_reply": "2024-10-19T03:18:16.511279Z"
    },
    "papermill": {
     "duration": 14.62501,
     "end_time": "2024-10-19T03:18:16.515509",
     "exception": false,
     "start_time": "2024-10-19T03:18:01.890499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the tokenizer and fit it on the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Convert the text to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences to ensure uniform input length (e.g., max_len=100)\n",
    "max_len = 50  # Maximum length of sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 because the tokenizer index starts at 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554fc3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:16.536500Z",
     "iopub.status.busy": "2024-10-19T03:18:16.535728Z",
     "iopub.status.idle": "2024-10-19T03:18:16.550152Z",
     "shell.execute_reply": "2024-10-19T03:18:16.548915Z"
    },
    "papermill": {
     "duration": 0.027748,
     "end_time": "2024-10-19T03:18:16.552890",
     "exception": false,
     "start_time": "2024-10-19T03:18:16.525142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stratify ensures that the class proportions are maintained across splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "667ebbb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:16.573330Z",
     "iopub.status.busy": "2024-10-19T03:18:16.572894Z",
     "iopub.status.idle": "2024-10-19T03:18:16.916511Z",
     "shell.execute_reply": "2024-10-19T03:18:16.915201Z"
    },
    "papermill": {
     "duration": 0.356657,
     "end_time": "2024-10-19T03:18:16.919217",
     "exception": false,
     "start_time": "2024-10-19T03:18:16.562560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: False    6535\n",
      "True     1148\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: False    1148\n",
      "True     1148\n",
      "Name: count, dtype: int64\n",
      "Original validation class distribution: False    2179\n",
      "True      382\n",
      "Name: count, dtype: int64\n",
      "Resampled validation class distribution: False    382\n",
      "True     382\n",
      "Name: count, dtype: int64\n",
      "Original test class distribution: False    2190\n",
      "True      371\n",
      "Name: count, dtype: int64\n",
      "Resampled test class distribution: False    371\n",
      "True     371\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Assuming X_train is your feature matrix and y_train is your target (label)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Perform undersampling\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "X_val_resampled, y_val_resampled = undersampler.fit_resample(X_val, y_val)\n",
    "X_test_resampled, y_test_resampled = undersampler.fit_resample(X_test, y_test)\n",
    "\n",
    "# Check the new class distribution after undersampling\n",
    "print(\"Original class distribution:\", pd.Series(y_train).value_counts())\n",
    "print(\"Resampled class distribution:\", pd.Series(y_train_resampled).value_counts())\n",
    "print(\"Original validation class distribution:\", pd.Series(y_val).value_counts())\n",
    "print(\"Resampled validation class distribution:\", pd.Series(y_val_resampled).value_counts())\n",
    "print(\"Original test class distribution:\", pd.Series(y_test).value_counts())\n",
    "print(\"Resampled test class distribution:\", pd.Series(y_test_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00749775",
   "metadata": {
    "papermill": {
     "duration": 0.008775,
     "end_time": "2024-10-19T03:18:16.937494",
     "exception": false,
     "start_time": "2024-10-19T03:18:16.928719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenizing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c26de78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:16.958534Z",
     "iopub.status.busy": "2024-10-19T03:18:16.957310Z",
     "iopub.status.idle": "2024-10-19T03:18:16.965477Z",
     "shell.execute_reply": "2024-10-19T03:18:16.964308Z"
    },
    "papermill": {
     "duration": 0.021139,
     "end_time": "2024-10-19T03:18:16.967856",
     "exception": false,
     "start_time": "2024-10-19T03:18:16.946717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(vocab, glove_file='glove.6B.50d.txt', embedding_dim=50):\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    # Load GloVe embeddings\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    \n",
    "    # Create embedding matrix for our vocabulary\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in vocab.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bf0287a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:16.988039Z",
     "iopub.status.busy": "2024-10-19T03:18:16.987622Z",
     "iopub.status.idle": "2024-10-19T03:18:22.770170Z",
     "shell.execute_reply": "2024-10-19T03:18:22.768890Z"
    },
    "papermill": {
     "duration": 5.812259,
     "end_time": "2024-10-19T03:18:22.789314",
     "exception": false,
     "start_time": "2024-10-19T03:18:16.977055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load GloVe embeddings for the tokenizer vocabulary\n",
    "embedding_matrix = load_glove_embeddings(tokenizer.word_index, '/kaggle/input/glove-embeddings/glove.6B.50d.txt', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40e68c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:22.809814Z",
     "iopub.status.busy": "2024-10-19T03:18:22.809377Z",
     "iopub.status.idle": "2024-10-19T03:18:22.854039Z",
     "shell.execute_reply": "2024-10-19T03:18:22.852950Z"
    },
    "papermill": {
     "duration": 0.05774,
     "end_time": "2024-10-19T03:18:22.856665",
     "exception": false,
     "start_time": "2024-10-19T03:18:22.798925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are your NumPy arrays or padded sequences\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train_resampled, dtype=torch.float32)  # Assuming binary classification\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_resampled, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test_resampled, dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_resampled, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val_resampled, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Create TensorDataset (combines inputs and labels)\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c65bb12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:22.877031Z",
     "iopub.status.busy": "2024-10-19T03:18:22.876620Z",
     "iopub.status.idle": "2024-10-19T03:18:22.890369Z",
     "shell.execute_reply": "2024-10-19T03:18:22.888985Z"
    },
    "papermill": {
     "duration": 0.02682,
     "end_time": "2024-10-19T03:18:22.892784",
     "exception": false,
     "start_time": "2024-10-19T03:18:22.865964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers,embedding_matrix, drop_prob=0.01):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # If GloVe embeddings are provided, use them; otherwise, initialize randomly\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n",
    "        else:\n",
    "            #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "            # Load BERT tokenizer and model\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "            self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "     # Initialize hidden state for the current batch size\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "       \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a9585",
   "metadata": {
    "papermill": {
     "duration": 0.00887,
     "end_time": "2024-10-19T03:18:22.910949",
     "exception": false,
     "start_time": "2024-10-19T03:18:22.902079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Instantiate the network\n",
    "\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n",
    "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3\n",
    "\n",
    "> Define the model  hyperparameters.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91ab8b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:22.931604Z",
     "iopub.status.busy": "2024-10-19T03:18:22.931127Z",
     "iopub.status.idle": "2024-10-19T03:18:22.961669Z",
     "shell.execute_reply": "2024-10-19T03:18:22.960430Z"
    },
    "papermill": {
     "duration": 0.044153,
     "end_time": "2024-10-19T03:18:22.964736",
     "exception": false,
     "start_time": "2024-10-19T03:18:22.920583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(20637, 50)\n",
      "  (lstm): LSTM(50, 256, num_layers=2, batch_first=True, dropout=0.01)\n",
      "  (dropout): Dropout(p=0.01, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "output_size = 1\n",
    "embedding_dim = 50\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "num_epochs=6\n",
    "# Initialize the model\n",
    "model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, embedding_matrix=embedding_matrix)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2197be1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:22.985365Z",
     "iopub.status.busy": "2024-10-19T03:18:22.984935Z",
     "iopub.status.idle": "2024-10-19T03:18:23.512955Z",
     "shell.execute_reply": "2024-10-19T03:18:23.511759Z"
    },
    "papermill": {
     "duration": 0.541649,
     "end_time": "2024-10-19T03:18:23.515785",
     "exception": false,
     "start_time": "2024-10-19T03:18:22.974136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "279c6ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:18:23.537270Z",
     "iopub.status.busy": "2024-10-19T03:18:23.535984Z",
     "iopub.status.idle": "2024-10-19T03:19:18.594991Z",
     "shell.execute_reply": "2024-10-19T03:19:18.593228Z"
    },
    "papermill": {
     "duration": 55.073001,
     "end_time": "2024-10-19T03:19:18.598288",
     "exception": false,
     "start_time": "2024-10-19T03:18:23.525287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/6... Step: 100... Loss: 0.690578... Val Loss: 0.691167\n",
      "Epoch: 3/6... Step: 200... Loss: 0.689891... Val Loss: 0.697322\n",
      "Epoch: 5/6... Step: 300... Loss: 0.625658... Val Loss: 0.693707\n",
      "Epoch: 6/6... Step: 400... Loss: 0.629568... Val Loss: 0.680452\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# Train the model (simplified training loop)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        hidden = tuple([each.data for each in hidden])  # Detach hidden states\n",
    "        counter += 1\n",
    "        # Zero the gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output, hidden = model(inputs, hidden)\n",
    "        \n",
    "        # Loss and backward pass\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5734e7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T03:19:18.620950Z",
     "iopub.status.busy": "2024-10-19T03:19:18.620500Z",
     "iopub.status.idle": "2024-10-19T03:19:19.719806Z",
     "shell.execute_reply": "2024-10-19T03:19:19.718494Z"
    },
    "papermill": {
     "duration": 1.113425,
     "end_time": "2024-10-19T03:19:19.722283",
     "exception": false,
     "start_time": "2024-10-19T03:19:18.608858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.699\n",
      "Test accuracy: 0.558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.89      0.67       371\n",
      "        True       0.67      0.23      0.34       371\n",
      "\n",
      "    accuracy                           0.56       742\n",
      "   macro avg       0.60      0.56      0.50       742\n",
      "weighted avg       0.60      0.56      0.50       742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = model.init_hidden(batch_size)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = model(inputs, h)\n",
    "   \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    " \n",
    "    y_pred.extend(pred.bool())\n",
    "    y_true.extend(labels.bool())\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    \n",
    "    \n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "   \n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=['False', 'True'])\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4294430,
     "sourceId": 7388005,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5823475,
     "sourceId": 9556937,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5890297,
     "sourceId": 9645101,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.521629,
   "end_time": "2024-10-19T03:19:22.198894",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T03:17:48.677265",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
