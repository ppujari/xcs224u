{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7388005,"sourceType":"datasetVersion","datasetId":4294430},{"sourceId":9556937,"sourceType":"datasetVersion","datasetId":5823475}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Network with PyTorch- Network Architecture\n\nBelow is where you'll define the network.\n\n<img src=\"assets/network_diagram.png\" width=40%>\n\nThe layers are as follows:\n1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n\n### The Embedding Layer\n\nWe need to add an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) because there are 74000+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n\n\n### The LSTM Layer(s)\n\nWe'll create an [LSTM](https://pytorch.org/docs/stable/nn.html#lstm) to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter.\n\nMost of the time, you're network will have better performance with more layers; between 2-3. Adding more layers allows the network to learn really complex relationships. \n\n> **Here implement:** Complete the `__init__`, `forward`, and `init_hidden` functions for the SentimentRNN model class.\n\nNote: `init_hidden` should initialize the hidden and cell state of an lstm layer to all zeros, and move those state to GPU, if available.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-13T16:49:54.571590Z","iopub.execute_input":"2024-10-13T16:49:54.572022Z","iopub.status.idle":"2024-10-13T16:49:54.605096Z","shell.execute_reply.started":"2024-10-13T16:49:54.571980Z","shell.execute_reply":"2024-10-13T16:49:54.603569Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import fbeta_score\nfrom IPython.display import Image\nfrom transformers import BertTokenizer, BertModel\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:07.445612Z","iopub.execute_input":"2024-10-30T19:28:07.446847Z","iopub.status.idle":"2024-10-30T19:28:15.024385Z","shell.execute_reply.started":"2024-10-30T19:28:07.446757Z","shell.execute_reply":"2024-10-30T19:28:15.023079Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nclass SentimentRNN(nn.Module):\n    def __init__(self, embedding_dim, hidden_dim, output_dim, n_layers=2, dropout=0.2):\n        super(SentimentRNN, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.dropout = nn.Dropout(dropout)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)  # Set batch_first=True\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n        \n    def init_hidden(self, batch_size):\n        # Initialize hidden state with shape (n_layers, batch_size, hidden_dim)\n        return (torch.zeros(self.n_layers, batch_size, self.hidden_dim),\n                torch.zeros(self.n_layers, batch_size, self.hidden_dim))\n\n    def forward(self, x):\n        # LSTM forward pass\n        out, _ = self.lstm(x)\n        # Take the output of the last time step\n        out = out[:, -1, :]\n        # Pass through a fully connected layer\n        out = self.fc(out)\n        sig_out = self.sig(out)\n \n        return sig_out\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.026903Z","iopub.execute_input":"2024-10-30T19:28:15.027461Z","iopub.status.idle":"2024-10-30T19:28:15.038734Z","shell.execute_reply.started":"2024-10-30T19:28:15.027418Z","shell.execute_reply":"2024-10-30T19:28:15.037312Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# First checking if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.040577Z","iopub.execute_input":"2024-10-30T19:28:15.041043Z","iopub.status.idle":"2024-10-30T19:28:15.051661Z","shell.execute_reply.started":"2024-10-30T19:28:15.040990Z","shell.execute_reply":"2024-10-30T19:28:15.050232Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/formspring-csv/formspring.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.055125Z","iopub.execute_input":"2024-10-30T19:28:15.055675Z","iopub.status.idle":"2024-10-30T19:28:15.277328Z","shell.execute_reply.started":"2024-10-30T19:28:15.055618Z","shell.execute_reply":"2024-10-30T19:28:15.276149Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.drop(['post', 'asker', 'bully1', 'bully2', 'bully3'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.278918Z","iopub.execute_input":"2024-10-30T19:28:15.279442Z","iopub.status.idle":"2024-10-30T19:28:15.298552Z","shell.execute_reply.started":"2024-10-30T19:28:15.279385Z","shell.execute_reply":"2024-10-30T19:28:15.297103Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def impute_ans_columns(value):\n    v = ['No','nan']\n    if value in v:\n        return 0\n    return 1","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.300384Z","iopub.execute_input":"2024-10-30T19:28:15.300805Z","iopub.status.idle":"2024-10-30T19:28:15.306835Z","shell.execute_reply.started":"2024-10-30T19:28:15.300740Z","shell.execute_reply":"2024-10-30T19:28:15.305483Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for col in ['ans1', 'ans2', 'ans3']:\n    df[col] = df[col].apply(impute_ans_columns)\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.308372Z","iopub.execute_input":"2024-10-30T19:28:15.308864Z","iopub.status.idle":"2024-10-30T19:28:15.379110Z","shell.execute_reply.started":"2024-10-30T19:28:15.308808Z","shell.execute_reply":"2024-10-30T19:28:15.377867Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                userid                                               ques  \\\n9085       kellyblake1  have you missed me?... i feel as though i&#039...   \n1783         teaachgee  Name a movie or movies you can watch over and ...   \n1353         teaachgee            Have you ever found a four leaf clover?   \n8020          avlarios                         THEY&#039;RE BE DOUCHEBAGS   \n12723       outlaw9000  Who can you picture spending your entire life ...   \n7297           zooshay  Would you mind if your boyfriend went out to p...   \n3425   tabithalocascio  Tabi. If you stopped hating on Texas everyone ...   \n8879       kellyblake1               Do you miss someone a lot right now?   \n850          teaachgee                                     Current worry?   \n6726           zooshay       to you whats the best thing about austraila?   \n\n                                                     ans  ans1 severity1  \\\n9085    Yeah  I had noticed :( Any particular reason?...     0         0   \n1783                  Juno  Sweet november  mr. deeds :]     0         0   \n1353                                   Nope  has anyone?     0         0   \n8020                     SHOVE A PENIS DOWN THEIR THROAT     1         8   \n12723   It used to be my Wife  but she is out of my L...     0         0   \n7297    nope if he dont mind me doing stuff without h...     0         0   \n3425    ummmm jack screw you  not my fault people get...     0         0   \n8879    I do  but I think its going down  like how mu...     0         0   \n850     how to survive in this crazy khaos of a world...     0         0   \n6726    ill have to say the beaches all year round th...     0         0   \n\n       ans2 severity2  ans3 severity3  \n9085      0         0     0         0  \n1783      0       NaN     0         0  \n1353      0         0     0         0  \n8020      1       NaN     1       NaN  \n12723     0         0     0         0  \n7297      0         0     0         0  \n3425      0         0     0         0  \n8879      0         0     0         0  \n850       0         0     0         0  \n6726      0         0     0         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>ans1</th>\n      <th>severity1</th>\n      <th>ans2</th>\n      <th>severity2</th>\n      <th>ans3</th>\n      <th>severity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9085</th>\n      <td>kellyblake1</td>\n      <td>have you missed me?... i feel as though i&amp;#039...</td>\n      <td>Yeah  I had noticed :( Any particular reason?...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1783</th>\n      <td>teaachgee</td>\n      <td>Name a movie or movies you can watch over and ...</td>\n      <td>Juno  Sweet november  mr. deeds :]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1353</th>\n      <td>teaachgee</td>\n      <td>Have you ever found a four leaf clover?</td>\n      <td>Nope  has anyone?</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8020</th>\n      <td>avlarios</td>\n      <td>THEY&amp;#039;RE BE DOUCHEBAGS</td>\n      <td>SHOVE A PENIS DOWN THEIR THROAT</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12723</th>\n      <td>outlaw9000</td>\n      <td>Who can you picture spending your entire life ...</td>\n      <td>It used to be my Wife  but she is out of my L...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7297</th>\n      <td>zooshay</td>\n      <td>Would you mind if your boyfriend went out to p...</td>\n      <td>nope if he dont mind me doing stuff without h...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3425</th>\n      <td>tabithalocascio</td>\n      <td>Tabi. If you stopped hating on Texas everyone ...</td>\n      <td>ummmm jack screw you  not my fault people get...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8879</th>\n      <td>kellyblake1</td>\n      <td>Do you miss someone a lot right now?</td>\n      <td>I do  but I think its going down  like how mu...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>850</th>\n      <td>teaachgee</td>\n      <td>Current worry?</td>\n      <td>how to survive in this crazy khaos of a world...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6726</th>\n      <td>zooshay</td>\n      <td>to you whats the best thing about austraila?</td>\n      <td>ill have to say the beaches all year round th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def impute_severity_columns(value):\n    '''Value will be a string. We need to convert it to int'''\n    v = ['nan', 'None', '0']\n    if value in v:\n        return 0\n    try:\n        return int(value)\n    except ValueError as e:\n        #print(value)\n        return 5","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.380934Z","iopub.execute_input":"2024-10-30T19:28:15.381445Z","iopub.status.idle":"2024-10-30T19:28:15.388839Z","shell.execute_reply.started":"2024-10-30T19:28:15.381389Z","shell.execute_reply":"2024-10-30T19:28:15.387544Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for col in ['severity1', 'severity2', 'severity3']:\n    df[col] = df[col].apply(impute_severity_columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.390444Z","iopub.execute_input":"2024-10-30T19:28:15.390948Z","iopub.status.idle":"2024-10-30T19:28:15.440030Z","shell.execute_reply.started":"2024-10-30T19:28:15.390904Z","shell.execute_reply":"2024-10-30T19:28:15.439009Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df['IsBully'] = (\n    (df.ans1 * df.severity1 + df.ans2 * df.severity2 + df.ans3 * df.severity3) / 30) >= 0.0333\n\n# Remove uneccessary columns\ndf_2 = df.drop(['userid','ans1', 'severity1','ans2','severity2','ans3','severity3'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.445643Z","iopub.execute_input":"2024-10-30T19:28:15.446040Z","iopub.status.idle":"2024-10-30T19:28:15.458890Z","shell.execute_reply.started":"2024-10-30T19:28:15.446001Z","shell.execute_reply":"2024-10-30T19:28:15.457605Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_2.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.460570Z","iopub.execute_input":"2024-10-30T19:28:15.461004Z","iopub.status.idle":"2024-10-30T19:28:15.477012Z","shell.execute_reply.started":"2024-10-30T19:28:15.460945Z","shell.execute_reply":"2024-10-30T19:28:15.475715Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                    ques  \\\n10088      Hows Lifeee Now Thaaat Yoooh Knoeee Thuhhh As   \n2900                     Lmao but then alix will see mee   \n9687   We need some more girls in here  theres Too ma...   \n12145  one memorable quote you remember from a song? ...   \n12569  What type of sexual performance do you preform...   \n3067   haha so many people are hating on your formspr...   \n1364   Have you ever had a poem or a song written abo...   \n8991    fight for the one or settle for someone amazing?   \n884                Do any of your friends have children?   \n9848      What would you want written on your tombstone?   \n\n                                                     ans  IsBully  \n10088            Lmao  Great . (: Couldntt Bee Betterr .    False  \n2900    lol how bout ya give it tew mi nd iWont accep...     True  \n9687                             I don't like that song.    False  \n12145   Keep your drink  just give me the Money. : Pi...    False  \n12569   Intercourse with women Oral with Men. I like ...    False  \n3067                              Juss krista as usual..    False  \n1364                                           yes lots.    False  \n8991    Hmmm  well 'the one' may not actually be the ...    False  \n884                                          yes they do    False  \n9848    OMG! I haven't even thought about it lol. I d...    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10088</th>\n      <td>Hows Lifeee Now Thaaat Yoooh Knoeee Thuhhh As</td>\n      <td>Lmao  Great . (: Couldntt Bee Betterr .</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2900</th>\n      <td>Lmao but then alix will see mee</td>\n      <td>lol how bout ya give it tew mi nd iWont accep...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9687</th>\n      <td>We need some more girls in here  theres Too ma...</td>\n      <td>I don't like that song.</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12145</th>\n      <td>one memorable quote you remember from a song? ...</td>\n      <td>Keep your drink  just give me the Money. : Pi...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12569</th>\n      <td>What type of sexual performance do you preform...</td>\n      <td>Intercourse with women Oral with Men. I like ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3067</th>\n      <td>haha so many people are hating on your formspr...</td>\n      <td>Juss krista as usual..</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1364</th>\n      <td>Have you ever had a poem or a song written abo...</td>\n      <td>yes lots.</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8991</th>\n      <td>fight for the one or settle for someone amazing?</td>\n      <td>Hmmm  well 'the one' may not actually be the ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>884</th>\n      <td>Do any of your friends have children?</td>\n      <td>yes they do</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9848</th>\n      <td>What would you want written on your tombstone?</td>\n      <td>OMG! I haven't even thought about it lol. I d...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for col in ['ques', 'ans']:\n    df_2[col] = df_2[col].str.replace(\"&#039;\", \"'\") # Put back the apostrophe\n\n    df_2[col] = df_2[col].str.replace(\"<br>\", \"\") \n    df_2[col] = df_2[col].str.replace(\"&quot;\", \"\") \n    #df_2[col] = df_2[col].str.replace(\"<3\", \"love\")","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.478553Z","iopub.execute_input":"2024-10-30T19:28:15.479529Z","iopub.status.idle":"2024-10-30T19:28:15.528943Z","shell.execute_reply.started":"2024-10-30T19:28:15.479471Z","shell.execute_reply":"2024-10-30T19:28:15.527877Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df_2 = df_2.dropna(how='all')","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.530432Z","iopub.execute_input":"2024-10-30T19:28:15.531008Z","iopub.status.idle":"2024-10-30T19:28:15.543214Z","shell.execute_reply.started":"2024-10-30T19:28:15.530951Z","shell.execute_reply":"2024-10-30T19:28:15.541846Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_2.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.544912Z","iopub.execute_input":"2024-10-30T19:28:15.545548Z","iopub.status.idle":"2024-10-30T19:28:15.559477Z","shell.execute_reply.started":"2024-10-30T19:28:15.545489Z","shell.execute_reply":"2024-10-30T19:28:15.558298Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                ques  \\\n0                      what's your favorite song? :D   \n1                                                 <3   \n2                            hey angel  you duh sexy   \n3                                                 (:   \n4  ******************MEOWWW*************************   \n\n                                         ans  IsBully  \n0   I like too many songs to have a favorite    False  \n1                         </3 ? haha jk! <33    False  \n2                   Really?!?! Thanks?! haha    False  \n3                                         ;(    False  \n4                                    *RAWR*?    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what's your favorite song? :D</td>\n      <td>I like too many songs to have a favorite</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;3</td>\n      <td>&lt;/3 ? haha jk! &lt;33</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy</td>\n      <td>Really?!?! Thanks?! haha</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(:</td>\n      <td>;(</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>******************MEOWWW*************************</td>\n      <td>*RAWR*?</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_2['ques_ans'] = df_2['ques'] + ' ' + df_2['ans'] ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.561116Z","iopub.execute_input":"2024-10-30T19:28:15.561568Z","iopub.status.idle":"2024-10-30T19:28:15.584340Z","shell.execute_reply.started":"2024-10-30T19:28:15.561507Z","shell.execute_reply":"2024-10-30T19:28:15.583076Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_2.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.585843Z","iopub.execute_input":"2024-10-30T19:28:15.586267Z","iopub.status.idle":"2024-10-30T19:28:15.604005Z","shell.execute_reply.started":"2024-10-30T19:28:15.586225Z","shell.execute_reply":"2024-10-30T19:28:15.602680Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                ques  \\\n0                      what's your favorite song? :D   \n1                                                 <3   \n2                            hey angel  you duh sexy   \n3                                                 (:   \n4  ******************MEOWWW*************************   \n\n                                         ans  IsBully  \\\n0   I like too many songs to have a favorite    False   \n1                         </3 ? haha jk! <33    False   \n2                   Really?!?! Thanks?! haha    False   \n3                                         ;(    False   \n4                                    *RAWR*?    False   \n\n                                            ques_ans  \n0  what's your favorite song? :D  I like too many...  \n1                             <3  </3 ? haha jk! <33  \n2  hey angel  you duh sexy  Really?!?! Thanks?! haha  \n3                                             (:  ;(  \n4  ******************MEOWWW**********************...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n      <th>ques_ans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what's your favorite song? :D</td>\n      <td>I like too many songs to have a favorite</td>\n      <td>False</td>\n      <td>what's your favorite song? :D  I like too many...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;3</td>\n      <td>&lt;/3 ? haha jk! &lt;33</td>\n      <td>False</td>\n      <td>&lt;3  &lt;/3 ? haha jk! &lt;33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy</td>\n      <td>Really?!?! Thanks?! haha</td>\n      <td>False</td>\n      <td>hey angel  you duh sexy  Really?!?! Thanks?! haha</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(:</td>\n      <td>;(</td>\n      <td>False</td>\n      <td>(:  ;(</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>******************MEOWWW*************************</td>\n      <td>*RAWR*?</td>\n      <td>False</td>\n      <td>******************MEOWWW**********************...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_2.drop(['ques','ans'], axis=1)\ncolumns = ['ques_ans','IsBully']\ndf2_ordered = df_2[columns]\ndf2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n# Remove punctuation using regex\ndf2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.605567Z","iopub.execute_input":"2024-10-30T19:28:15.605993Z","iopub.status.idle":"2024-10-30T19:28:15.690122Z","shell.execute_reply.started":"2024-10-30T19:28:15.605949Z","shell.execute_reply":"2024-10-30T19:28:15.688846Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2035247237.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n/tmp/ipykernel_30/2035247237.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"df2_ordered = df2_ordered[df2_ordered['ques_ans'].notna()]  # Remove NaN values\ndf2_ordered = df2_ordered[df2_ordered['ques_ans'].str.strip() != '']  # Remove empty strings\ndf2_ordered.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.691468Z","iopub.execute_input":"2024-10-30T19:28:15.691835Z","iopub.status.idle":"2024-10-30T19:28:15.719540Z","shell.execute_reply.started":"2024-10-30T19:28:15.691795Z","shell.execute_reply":"2024-10-30T19:28:15.718372Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                            ques_ans  IsBully\n0  whats your favorite song d  i like too many so...    False\n1                                   3  3  haha jk 33    False\n2        hey angel  you duh sexy  really thanks haha    False\n4                                       meowww  rawr    False\n5  any makeup tips i suck at doing my makeup lol ...    False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques_ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>whats your favorite song d  i like too many so...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3  3  haha jk 33</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy  really thanks haha</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>meowww  rawr</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>any makeup tips i suck at doing my makeup lol ...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\n# Assuming X_train is your feature matrix and y_train is your target (label)\nundersampler = RandomUnderSampler(random_state=42)\n\n# Perform undersampling\nX_resampled, y_resampled = undersampler.fit_resample(df2_ordered['ques_ans'].values.reshape(-1, 1), df2_ordered['IsBully'])\n# Check the new class distribution after undersampling\n#print(\"Original class distribution:\", df2_ordered['ques_ans'].value_counts())\nprint(\"Resampled class distribution:\", pd.Series(y_resampled).value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:15.721291Z","iopub.execute_input":"2024-10-30T19:28:15.721839Z","iopub.status.idle":"2024-10-30T19:28:16.146867Z","shell.execute_reply.started":"2024-10-30T19:28:15.721757Z","shell.execute_reply":"2024-10-30T19:28:16.145719Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Resampled class distribution: IsBully\nFalse    1901\nTrue     1901\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"X = df2_ordered['ques_ans'].values\ny = df2_ordered['IsBully'].values","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:16.148502Z","iopub.execute_input":"2024-10-30T19:28:16.149281Z","iopub.status.idle":"2024-10-30T19:28:16.155088Z","shell.execute_reply.started":"2024-10-30T19:28:16.149225Z","shell.execute_reply":"2024-10-30T19:28:16.154043Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(X_resampled)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:16.156617Z","iopub.execute_input":"2024-10-30T19:28:16.157008Z","iopub.status.idle":"2024-10-30T19:28:16.167965Z","shell.execute_reply.started":"2024-10-30T19:28:16.156961Z","shell.execute_reply":"2024-10-30T19:28:16.166665Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[['what is the last film you saw  get him to the greek  fucking hilarious ']\n ['whaaat aree 5thingsss yoooh loveee about angieee ampamp ashely    i cantt evenn thinkk uvv o1  lett alonee o5  lmao ']\n ['why are you talking to people that you don39t even know just wondering  no']\n ...\n ['youre a bushwhacking  alchy piece of shit scrub  and youre blocked']\n ['your 44 years old o dumbass  pedifile d  you feel better now  if you dont want to talk to me  then just say so']\n ['if i told u den it would make it all the less fun  or it would make yuh loook like a person not a fake scaredyy cat ']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Cleanup upto here","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade openai","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:16.169659Z","iopub.execute_input":"2024-10-30T19:28:16.170365Z","iopub.status.idle":"2024-10-30T19:28:32.875991Z","shell.execute_reply.started":"2024-10-30T19:28:16.170322Z","shell.execute_reply":"2024-10-30T19:28:32.874248Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-1.53.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nCollecting jiter<1,>=0.4.0 (from openai)\n  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.9.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\nDownloading openai-1.53.0-py3-none-any.whl (387 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.1/387.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: jiter, openai\nSuccessfully installed jiter-0.6.1 openai-1.53.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:32.878168Z","iopub.execute_input":"2024-10-30T19:28:32.879152Z","iopub.status.idle":"2024-10-30T19:28:47.473610Z","shell.execute_reply.started":"2024-10-30T19:28:32.879101Z","shell.execute_reply":"2024-10-30T19:28:47.472180Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\nDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_model = \"text-embedding-3-small\"\nembedding_encoding = \"cl100k_base\"\nmax_tokens = 8000  # the maximum for text-embedding-3-small is 8191","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:47.475517Z","iopub.execute_input":"2024-10-30T19:28:47.475989Z","iopub.status.idle":"2024-10-30T19:28:47.481571Z","shell.execute_reply.started":"2024-10-30T19:28:47.475939Z","shell.execute_reply":"2024-10-30T19:28:47.480414Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from openai import OpenAI\napi_key = \"OPENAI_API+KEY\"\n\nclient = OpenAI(api_key=\"OPENAI_API_KEY\")\n\n\ndef get_embedding(text: str, model=\"text-embedding-3-large\", **kwargs):\n    # replace newlines, which can negatively affect performance.\n    text = text.replace(\"\\n\", \" \")\n\n    response = client.embeddings.create(input=[text], model=model, **kwargs)\n\n    return response.data[0].embedding\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:47.483258Z","iopub.execute_input":"2024-10-30T19:28:47.483725Z","iopub.status.idle":"2024-10-30T19:28:48.567243Z","shell.execute_reply.started":"2024-10-30T19:28:47.483674Z","shell.execute_reply":"2024-10-30T19:28:48.566203Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Reshape X_resampled and y_resampled if necessary\nX_resampled_np = X_resampled.reshape(-1) if X_resampled.ndim > 1 else X_resampled\ny_resampled_np = y_resampled.reshape(-1) if y_resampled.ndim > 1 else y_resampled\n\n# Now create the DataFrame\ndf_resampled = pd.DataFrame({\n    \"ques_ans\": X_resampled_np,\n    \"IsBully\": y_resampled_np\n})\n\ndf_resampled[\"embedding\"] = df_resampled[\"ques_ans\"].apply(lambda x: get_embedding(x))","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:28:48.568733Z","iopub.execute_input":"2024-10-30T19:28:48.569146Z","iopub.status.idle":"2024-10-30T19:50:17.626321Z","shell.execute_reply.started":"2024-10-30T19:28:48.569106Z","shell.execute_reply":"2024-10-30T19:50:17.624898Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df_resampled.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:17.628103Z","iopub.execute_input":"2024-10-30T19:50:17.628583Z","iopub.status.idle":"2024-10-30T19:50:17.650844Z","shell.execute_reply.started":"2024-10-30T19:50:17.628530Z","shell.execute_reply":"2024-10-30T19:50:17.649537Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                            ques_ans  IsBully  \\\n0  what is the last film you saw  get him to the ...    False   \n1  whaaat aree 5thingsss yoooh loveee about angie...    False   \n2  why are you talking to people that you don39t ...    False   \n3                do you own a striped sweater  i may    False   \n4  would you ever wait tables at a restaurant  i ...    False   \n\n                                           embedding  \n0  [-0.017185905948281288, 0.06371483206748962, -...  \n1  [-0.0150068374350667, 0.021200960502028465, -0...  \n2  [0.02681851200759411, 0.014757352881133556, -0...  \n3  [-0.07465637475252151, 0.02348770759999752, -0...  \n4  [-0.04610820114612579, -0.024261515587568283, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques_ans</th>\n      <th>IsBully</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is the last film you saw  get him to the ...</td>\n      <td>False</td>\n      <td>[-0.017185905948281288, 0.06371483206748962, -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>whaaat aree 5thingsss yoooh loveee about angie...</td>\n      <td>False</td>\n      <td>[-0.0150068374350667, 0.021200960502028465, -0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>why are you talking to people that you don39t ...</td>\n      <td>False</td>\n      <td>[0.02681851200759411, 0.014757352881133556, -0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>do you own a striped sweater  i may</td>\n      <td>False</td>\n      <td>[-0.07465637475252151, 0.02348770759999752, -0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>would you ever wait tables at a restaurant  i ...</td>\n      <td>False</td>\n      <td>[-0.04610820114612579, -0.024261515587568283, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We do not need to make same length as the embeddings are of fixed length.","metadata":{}},{"cell_type":"code","source":"## Convert embeddings to a list of lists, ensuring they are flattened\nembeddings_list = [embedding if isinstance(embedding[0], (float, int)) else embedding[0] for embedding in df_resampled[\"embedding\"].to_list()]\n\n# Convert to a PyTorch tensor\nembeddings_tensor = torch.tensor(embeddings_list, dtype=torch.float32).squeeze()\n\n# Check the shape\nprint(embeddings_tensor.shape)  # Should output (3802, 1536)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:17.658177Z","iopub.execute_input":"2024-10-30T19:50:17.658591Z","iopub.status.idle":"2024-10-30T19:50:19.198213Z","shell.execute_reply.started":"2024-10-30T19:50:17.658549Z","shell.execute_reply":"2024-10-30T19:50:19.197045Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"torch.Size([3802, 3072])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(embeddings_tensor.shape) ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:19.199985Z","iopub.execute_input":"2024-10-30T19:50:19.200462Z","iopub.status.idle":"2024-10-30T19:50:19.207078Z","shell.execute_reply.started":"2024-10-30T19:50:19.200409Z","shell.execute_reply":"2024-10-30T19:50:19.205896Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"torch.Size([3802, 3072])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tokenizing and Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Instantiate the network\n​\nHere, we'll instantiate the network. First up, defining the hyperparameters.\n​\n* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n* `n_layers`: Number of LSTM layers in the network. Typically between 1-3\n​\n> Define the model  hyperparameters.\n​","metadata":{}},{"cell_type":"code","source":"# Assume embeddings_data is a list of embeddings for each text\nhidden_dim = 128\noutput_dim = 1\nbatch_size = 32\nembedding_dim = embeddings_tensor.shape[1]\nmodel = SentimentRNN(embedding_dim, hidden_dim, output_dim)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:19.208629Z","iopub.execute_input":"2024-10-30T19:50:19.209036Z","iopub.status.idle":"2024-10-30T19:50:19.258719Z","shell.execute_reply.started":"2024-10-30T19:50:19.208988Z","shell.execute_reply":"2024-10-30T19:50:19.257433Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# loss and optimization functions\nlr=0.001\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:19.260365Z","iopub.execute_input":"2024-10-30T19:50:19.261283Z","iopub.status.idle":"2024-10-30T19:50:19.878342Z","shell.execute_reply.started":"2024-10-30T19:50:19.261222Z","shell.execute_reply":"2024-10-30T19:50:19.877231Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Since LSTMs expect a 3D tensor of shape (batch_size, sequence_length, embedding_dim), you need to add a sequence dimension to your embeddings. For each input sentence embedding, the sequence length is 1, as you only have a single embedding vector per sentence.","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    embeddings_tensor.numpy(),  # Convert to NumPy array for splitting\n    y_resampled,               # Labels\n    test_size=0.2, \n    shuffle=True,\n    random_state=42            \n)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15,random_state=42, shuffle=True)\n\n# Convert the split data back to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32).squeeze()  # Shape: (num_train_samples, 1, embedding_dim)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).squeeze()    # Shape: (num_test_samples, 1, embedding_dim)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32).squeeze()   # Shape: (num_test_samples, 1, embedding_dim)\n\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)  # Shape: (num_train_samples, 1)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)    # Shape: (num_test_samples, 1)\ny_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)    # Shape: (num_test_samples, 1)\n\n# Check shapes to ensure correctness\nprint(\"Training set shapes:\", X_train_tensor.shape, y_train_tensor.shape)\nprint(\"Testing set shapes:\", X_test_tensor.shape, y_test_tensor.shape)\nprint(\"Validation set shapes:\", X_val_tensor.shape, y_val_tensor.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:19.879839Z","iopub.execute_input":"2024-10-30T19:50:19.880615Z","iopub.status.idle":"2024-10-30T19:50:19.978933Z","shell.execute_reply.started":"2024-10-30T19:50:19.880555Z","shell.execute_reply":"2024-10-30T19:50:19.977667Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Training set shapes: torch.Size([2584, 3072]) torch.Size([2584, 1])\nTesting set shapes: torch.Size([761, 3072]) torch.Size([761, 1])\nValidation set shapes: torch.Size([457, 3072]) torch.Size([457, 1])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create TensorDataset (combines inputs and labels)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\n# Create DataLoader for training and testing sets\nbatch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T19:50:19.980786Z","iopub.execute_input":"2024-10-30T19:50:19.981172Z","iopub.status.idle":"2024-10-30T19:50:19.988677Z","shell.execute_reply.started":"2024-10-30T19:50:19.981130Z","shell.execute_reply":"2024-10-30T19:50:19.987314Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"num_epochs = 4\nclip = 5  # Gradient clipping value\ncounter = 0\nprint_every = 100\nmodel.train()\nfor epoch in range(num_epochs):\n    for embeddings_batch, labels_batch in train_loader:\n\n        # Move data to the device if using GPU\n        embeddings_batch, labels_batch = embeddings_batch.to(device), labels_batch.to(device)\n        embeddings_batch = embeddings_batch.unsqueeze(1)\n        # Zero gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(embeddings_batch)\n     \n        # Calculate loss\n        loss = criterion(outputs.squeeze(1), labels_batch.squeeze(1))\n        \n        # Backward pass and optimization\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        \n        # Optimizer step\n        optimizer.step()\n        \n        # Increment step counter\n        counter += 1\n\n        # Print loss and validation loss every `print_every` steps\n        if counter % print_every == 0:\n            val_losses = []\n            model.eval()  # Set model to evaluation mode\n            \n            with torch.no_grad():  # Disable gradient calculation for validation\n                for inputs, labels in valid_loader:\n                    inputs, labels = inputs.to(device), labels.to(device)  # Move to device\n                    output = model(inputs.unsqueeze(1))\n                    val_loss = criterion(output, labels)\n                    val_losses.append(val_loss.item())\n            \n            model.train()  # Set model back to training mode\n            \n            # Print training and validation losses\n            print(\"Epoch: {}/{}...\".format(epoch + 1, num_epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T20:07:38.176733Z","iopub.execute_input":"2024-10-30T20:07:38.177232Z","iopub.status.idle":"2024-10-30T20:07:47.731243Z","shell.execute_reply.started":"2024-10-30T20:07:38.177187Z","shell.execute_reply":"2024-10-30T20:07:47.730110Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch: 2/4... Step: 100... Loss: 0.563460... Val Loss: 0.596806\nEpoch: 3/4... Step: 200... Loss: 0.629637... Val Loss: 0.587182\nEpoch: 4/4... Step: 300... Loss: 0.568587... Val Loss: 0.577696\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get test data loss and accuracy\n\ntest_losses = [] # track loss\nnum_correct = 0\n\ny_pred = []\ny_true = []\nmodel.eval()\n# iterate over test data\nfor inputs, labels in test_loader:\n    \n    # get predicted outputs\n    output = model(inputs.unsqueeze(1))\n   \n   \n    # calculate loss\n    test_loss = criterion(output, labels.float())\n    test_losses.append(test_loss.item())\n    \n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n\n   \n    y_pred.extend(pred.bool())\n    y_true.extend(labels.bool())\n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.view_as(pred).float())\n    #correct_tensor = pred.eq(labels.float().view_as(pred))\n    \n    \n    correct = np.squeeze(correct_tensor.numpy())\n   \n    num_correct += np.sum(correct)\n\n\n# -- stats! -- ##\n# avg test loss\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n\n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))\n\n# Generate classification report\nreport = classification_report(y_true, y_pred, target_names=['False', 'True'])\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T20:07:53.915066Z","iopub.execute_input":"2024-10-30T20:07:53.915616Z","iopub.status.idle":"2024-10-30T20:07:54.208965Z","shell.execute_reply.started":"2024-10-30T20:07:53.915567Z","shell.execute_reply":"2024-10-30T20:07:54.207507Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Test loss: 0.611\nTest accuracy: 0.799\n              precision    recall  f1-score   support\n\n       False       0.80      0.83      0.81       401\n        True       0.80      0.77      0.78       360\n\n    accuracy                           0.80       761\n   macro avg       0.80      0.80      0.80       761\nweighted avg       0.80      0.80      0.80       761\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}