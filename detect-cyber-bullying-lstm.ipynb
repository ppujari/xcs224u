{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7388005,"sourceType":"datasetVersion","datasetId":4294430},{"sourceId":9556937,"sourceType":"datasetVersion","datasetId":5823475},{"sourceId":9645101,"sourceType":"datasetVersion","datasetId":5890297}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Network with PyTorch\n\nBelow is where you'll define the network.\n\n<img src=\"assets/network_diagram.png\" width=40%>\n\nThe layers are as follows:\n1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n\n### The Embedding Layer\n\nWe need to add an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) because there are 74000+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n\n\n### The LSTM Layer(s)\n\nWe'll create an [LSTM](https://pytorch.org/docs/stable/nn.html#lstm) to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter.\n\nMost of the time, you're network will have better performance with more layers; between 2-3. Adding more layers allows the network to learn really complex relationships. \n\n> **Here implement:** Complete the `__init__`, `forward`, and `init_hidden` functions for the SentimentRNN model class.\n\nNote: `init_hidden` should initialize the hidden and cell state of an lstm layer to all zeros, and move those state to GPU, if available.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-13T16:49:54.571590Z","iopub.execute_input":"2024-10-13T16:49:54.572022Z","iopub.status.idle":"2024-10-13T16:49:54.605096Z","shell.execute_reply.started":"2024-10-13T16:49:54.571980Z","shell.execute_reply":"2024-10-13T16:49:54.603569Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport string\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom transformers import BertTokenizer\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport re\nfrom sklearn.metrics import fbeta_score\nfrom IPython.display import Image\nfrom transformers import BertTokenizer, BertModel\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.084779Z","iopub.execute_input":"2024-10-19T03:13:10.085444Z","iopub.status.idle":"2024-10-19T03:13:10.097940Z","shell.execute_reply.started":"2024-10-19T03:13:10.085397Z","shell.execute_reply":"2024-10-19T03:13:10.096397Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"# First checking if GPU is available\ntrain_on_gpu=torch.cuda.is_available()\n\nif(train_on_gpu):\n    print('Training on GPU.')\nelse:\n    print('No GPU available, training on CPU.')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.100295Z","iopub.execute_input":"2024-10-19T03:13:10.100771Z","iopub.status.idle":"2024-10-19T03:13:10.114935Z","shell.execute_reply.started":"2024-10-19T03:13:10.100728Z","shell.execute_reply":"2024-10-19T03:13:10.113381Z"},"trusted":true},"execution_count":172,"outputs":[{"name":"stdout","text":"No GPU available, training on CPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/formspring-csv/formspring.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.117232Z","iopub.execute_input":"2024-10-19T03:13:10.117701Z","iopub.status.idle":"2024-10-19T03:13:10.236671Z","shell.execute_reply.started":"2024-10-19T03:13:10.117658Z","shell.execute_reply":"2024-10-19T03:13:10.235028Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"df.drop(['post', 'asker', 'bully1', 'bully2', 'bully3'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.238615Z","iopub.execute_input":"2024-10-19T03:13:10.239178Z","iopub.status.idle":"2024-10-19T03:13:10.252126Z","shell.execute_reply.started":"2024-10-19T03:13:10.239118Z","shell.execute_reply":"2024-10-19T03:13:10.250203Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"def impute_ans_columns(value):\n    v = ['No','nan']\n    if value in v:\n        return 0\n    return 1","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.255148Z","iopub.execute_input":"2024-10-19T03:13:10.255598Z","iopub.status.idle":"2024-10-19T03:13:10.265414Z","shell.execute_reply.started":"2024-10-19T03:13:10.255556Z","shell.execute_reply":"2024-10-19T03:13:10.263796Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"for col in ['ans1', 'ans2', 'ans3']:\n    df[col] = df[col].apply(impute_ans_columns)\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.267049Z","iopub.execute_input":"2024-10-19T03:13:10.267515Z","iopub.status.idle":"2024-10-19T03:13:10.315865Z","shell.execute_reply.started":"2024-10-19T03:13:10.267469Z","shell.execute_reply":"2024-10-19T03:13:10.314292Z"},"trusted":true},"execution_count":176,"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"                userid                                               ques  \\\n8642       kellyblake1    are you at all double-jointed? at all flexible?   \n5270           zooshay  Can you believe it I just got the fcuk off the...   \n11073       outlaw9000  captainthrash.tumblr.com I will love you forev...   \n3656          xxrachxx                    I said 666. The opposite of me.   \n12506       outlaw9000  What is your opinion on why parents are someti...   \n3480   tabithalocascio  Wait. Are you Cheyenne? I sent a request to yo...   \n12815       outlaw9000         would you ever have sex with an underage ?   \n6959           zooshay                   What is your definition of love?   \n9844       kellyblake1  What would you do if your girlfriend pulled a ...   \n5757           zooshay  hi sweetie  what&apos;s your msn contact? gmac...   \n\n                                                     ans  ans1 severity1  \\\n8642                         Not really no lol. Are you?     0         0   \n5270      holy was just about to ask u the same thing :O     0         0   \n11073                                              okies     0         0   \n3656    ...........999 a girl?? lol oh god why did u ...     0         0   \n12506                            we worry about our Kids     0         0   \n3480    no  im tabitha jai locascio. myspace.com/tabi...     0         0   \n12815   no. I talk dirty  but would never have that k...     0         0   \n6959                                          Zoowill =P     0         0   \n9844                                Do you mean cheated?     0         0   \n5757                          i gave it to u already lol     0         0   \n\n       ans2 severity2  ans3 severity3  \n8642      0         0     0         0  \n5270      0         0     0         0  \n11073     0         0     0         0  \n3656      0         0     0         0  \n12506     0         0     0         0  \n3480      0       NaN     0         0  \n12815     0         0     0         0  \n6959      0         0     0         0  \n9844      0         0     0         0  \n5757      0         0     0         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userid</th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>ans1</th>\n      <th>severity1</th>\n      <th>ans2</th>\n      <th>severity2</th>\n      <th>ans3</th>\n      <th>severity3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8642</th>\n      <td>kellyblake1</td>\n      <td>are you at all double-jointed? at all flexible?</td>\n      <td>Not really no lol. Are you?</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5270</th>\n      <td>zooshay</td>\n      <td>Can you believe it I just got the fcuk off the...</td>\n      <td>holy was just about to ask u the same thing :O</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11073</th>\n      <td>outlaw9000</td>\n      <td>captainthrash.tumblr.com I will love you forev...</td>\n      <td>okies</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>xxrachxx</td>\n      <td>I said 666. The opposite of me.</td>\n      <td>...........999 a girl?? lol oh god why did u ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12506</th>\n      <td>outlaw9000</td>\n      <td>What is your opinion on why parents are someti...</td>\n      <td>we worry about our Kids</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3480</th>\n      <td>tabithalocascio</td>\n      <td>Wait. Are you Cheyenne? I sent a request to yo...</td>\n      <td>no  im tabitha jai locascio. myspace.com/tabi...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12815</th>\n      <td>outlaw9000</td>\n      <td>would you ever have sex with an underage ?</td>\n      <td>no. I talk dirty  but would never have that k...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6959</th>\n      <td>zooshay</td>\n      <td>What is your definition of love?</td>\n      <td>Zoowill =P</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9844</th>\n      <td>kellyblake1</td>\n      <td>What would you do if your girlfriend pulled a ...</td>\n      <td>Do you mean cheated?</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5757</th>\n      <td>zooshay</td>\n      <td>hi sweetie  what&amp;apos;s your msn contact? gmac...</td>\n      <td>i gave it to u already lol</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def impute_severity_columns(value):\n    '''Value will be a string. We need to convert it to int'''\n    v = ['nan', 'None', '0']\n    if value in v:\n        return 0\n    try:\n        return int(value)\n    except ValueError as e:\n        #print(value)\n        return 5","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.317849Z","iopub.execute_input":"2024-10-19T03:13:10.318438Z","iopub.status.idle":"2024-10-19T03:13:10.327284Z","shell.execute_reply.started":"2024-10-19T03:13:10.318380Z","shell.execute_reply":"2024-10-19T03:13:10.325955Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"for col in ['severity1', 'severity2', 'severity3']:\n    df[col] = df[col].apply(impute_severity_columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.329552Z","iopub.execute_input":"2024-10-19T03:13:10.330112Z","iopub.status.idle":"2024-10-19T03:13:10.364225Z","shell.execute_reply.started":"2024-10-19T03:13:10.330057Z","shell.execute_reply":"2024-10-19T03:13:10.362979Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"df['IsBully'] = (\n    (df.ans1 * df.severity1 + df.ans2 * df.severity2 + df.ans3 * df.severity3) / 30) >= 0.0333\n\n# Remove uneccessary columns\ndf_2 = df.drop(['userid','ans1', 'severity1','ans2','severity2','ans3','severity3'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.365962Z","iopub.execute_input":"2024-10-19T03:13:10.366406Z","iopub.status.idle":"2024-10-19T03:13:10.384013Z","shell.execute_reply.started":"2024-10-19T03:13:10.366361Z","shell.execute_reply":"2024-10-19T03:13:10.382482Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"df_2.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.385907Z","iopub.execute_input":"2024-10-19T03:13:10.387302Z","iopub.status.idle":"2024-10-19T03:13:10.403816Z","shell.execute_reply.started":"2024-10-19T03:13:10.387232Z","shell.execute_reply":"2024-10-19T03:13:10.402193Z"},"trusted":true},"execution_count":180,"outputs":[{"execution_count":180,"output_type":"execute_result","data":{"text/plain":"                                                    ques  \\\n8795                Do you believe in Karma and Destiny?   \n2802   B!+(h !M@ B3 PUMP!N D!S$Z D!(k !N Y0 3@R S0 H@...   \n3491   What are your symptoms when you have fallen fo...   \n8282                                          I love you   \n2724                       Wait Nevermind I Am Signed In   \n9841                  what would you do if i kissed you?   \n662                            who is your bestfriend???   \n180                        whats ur fav tv showww? :D <3   \n11219  Do you have a favorite article of clothing ? W...   \n11621                                           Heyaaa !   \n\n                                                     ans  IsBully  \n8795    I would like to believe in those things  it i...    False  \n2802    hoe ass bxtch how bout ya show yo face pussy....     True  \n3491                                                  ;)    False  \n8282                                 I love you  too. c:    False  \n2724                                          Dumb ass(:     True  \n9841    Hmmm  there is 2 answers to this question :P ...    False  \n662                                           You are :)    False  \n180     Umm. . . good question i have many bhut i gue...    False  \n11219                                my Superman T Shirt    False  \n11621                                        hey Sweetie    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8795</th>\n      <td>Do you believe in Karma and Destiny?</td>\n      <td>I would like to believe in those things  it i...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2802</th>\n      <td>B!+(h !M@ B3 PUMP!N D!S$Z D!(k !N Y0 3@R S0 H@...</td>\n      <td>hoe ass bxtch how bout ya show yo face pussy....</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3491</th>\n      <td>What are your symptoms when you have fallen fo...</td>\n      <td>;)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8282</th>\n      <td>I love you</td>\n      <td>I love you  too. c:</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2724</th>\n      <td>Wait Nevermind I Am Signed In</td>\n      <td>Dumb ass(:</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9841</th>\n      <td>what would you do if i kissed you?</td>\n      <td>Hmmm  there is 2 answers to this question :P ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>who is your bestfriend???</td>\n      <td>You are :)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>whats ur fav tv showww? :D &lt;3</td>\n      <td>Umm. . . good question i have many bhut i gue...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11219</th>\n      <td>Do you have a favorite article of clothing ? W...</td>\n      <td>my Superman T Shirt</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11621</th>\n      <td>Heyaaa !</td>\n      <td>hey Sweetie</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for col in ['ques', 'ans']:\n    df_2[col] = df_2[col].str.replace(\"&#039;\", \"'\") # Put back the apostrophe\n\n    df_2[col] = df_2[col].str.replace(\"<br>\", \"\") \n    df_2[col] = df_2[col].str.replace(\"&quot;\", \"\") \n    #df_2[col] = df_2[col].str.replace(\"<3\", \"love\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.409655Z","iopub.execute_input":"2024-10-19T03:13:10.410253Z","iopub.status.idle":"2024-10-19T03:13:10.461097Z","shell.execute_reply.started":"2024-10-19T03:13:10.410186Z","shell.execute_reply":"2024-10-19T03:13:10.459444Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"df_2 = df_2.dropna(how='all')","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.463081Z","iopub.execute_input":"2024-10-19T03:13:10.463787Z","iopub.status.idle":"2024-10-19T03:13:10.481802Z","shell.execute_reply.started":"2024-10-19T03:13:10.463718Z","shell.execute_reply":"2024-10-19T03:13:10.480160Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"df_2.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.484448Z","iopub.execute_input":"2024-10-19T03:13:10.485089Z","iopub.status.idle":"2024-10-19T03:13:10.501595Z","shell.execute_reply.started":"2024-10-19T03:13:10.485030Z","shell.execute_reply":"2024-10-19T03:13:10.500055Z"},"trusted":true},"execution_count":183,"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"                                                ques  \\\n0                      what's your favorite song? :D   \n1                                                 <3   \n2                            hey angel  you duh sexy   \n3                                                 (:   \n4  ******************MEOWWW*************************   \n\n                                         ans  IsBully  \n0   I like too many songs to have a favorite    False  \n1                         </3 ? haha jk! <33    False  \n2                   Really?!?! Thanks?! haha    False  \n3                                         ;(    False  \n4                                    *RAWR*?    False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what's your favorite song? :D</td>\n      <td>I like too many songs to have a favorite</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;3</td>\n      <td>&lt;/3 ? haha jk! &lt;33</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy</td>\n      <td>Really?!?! Thanks?! haha</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(:</td>\n      <td>;(</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>******************MEOWWW*************************</td>\n      <td>*RAWR*?</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_2['ques_ans'] = df_2['ques'] + ' ' + df_2['ans'] ","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.503556Z","iopub.execute_input":"2024-10-19T03:13:10.504110Z","iopub.status.idle":"2024-10-19T03:13:10.531635Z","shell.execute_reply.started":"2024-10-19T03:13:10.504061Z","shell.execute_reply":"2024-10-19T03:13:10.530150Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"df_2.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.533901Z","iopub.execute_input":"2024-10-19T03:13:10.534418Z","iopub.status.idle":"2024-10-19T03:13:10.556829Z","shell.execute_reply.started":"2024-10-19T03:13:10.534371Z","shell.execute_reply":"2024-10-19T03:13:10.555272Z"},"trusted":true},"execution_count":185,"outputs":[{"execution_count":185,"output_type":"execute_result","data":{"text/plain":"                                                ques  \\\n0                      what's your favorite song? :D   \n1                                                 <3   \n2                            hey angel  you duh sexy   \n3                                                 (:   \n4  ******************MEOWWW*************************   \n\n                                         ans  IsBully  \\\n0   I like too many songs to have a favorite    False   \n1                         </3 ? haha jk! <33    False   \n2                   Really?!?! Thanks?! haha    False   \n3                                         ;(    False   \n4                                    *RAWR*?    False   \n\n                                            ques_ans  \n0  what's your favorite song? :D  I like too many...  \n1                             <3  </3 ? haha jk! <33  \n2  hey angel  you duh sexy  Really?!?! Thanks?! haha  \n3                                             (:  ;(  \n4  ******************MEOWWW**********************...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques</th>\n      <th>ans</th>\n      <th>IsBully</th>\n      <th>ques_ans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what's your favorite song? :D</td>\n      <td>I like too many songs to have a favorite</td>\n      <td>False</td>\n      <td>what's your favorite song? :D  I like too many...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;3</td>\n      <td>&lt;/3 ? haha jk! &lt;33</td>\n      <td>False</td>\n      <td>&lt;3  &lt;/3 ? haha jk! &lt;33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy</td>\n      <td>Really?!?! Thanks?! haha</td>\n      <td>False</td>\n      <td>hey angel  you duh sexy  Really?!?! Thanks?! haha</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(:</td>\n      <td>;(</td>\n      <td>False</td>\n      <td>(:  ;(</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>******************MEOWWW*************************</td>\n      <td>*RAWR*?</td>\n      <td>False</td>\n      <td>******************MEOWWW**********************...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_2.drop(['ques','ans'], axis=1)\ncolumns = ['ques_ans','IsBully']\ndf2_ordered = df_2[columns]\ndf2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n# Remove punctuation using regex\ndf2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.558599Z","iopub.execute_input":"2024-10-19T03:13:10.559320Z","iopub.status.idle":"2024-10-19T03:13:10.626891Z","shell.execute_reply.started":"2024-10-19T03:13:10.559098Z","shell.execute_reply":"2024-10-19T03:13:10.625502Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2035247237.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.lower()\n/tmp/ipykernel_30/2035247237.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df2_ordered['ques_ans'] = df2_ordered['ques_ans'].str.replace(f'[{string.punctuation}]', '', regex=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"df2_ordered = df2_ordered[df2_ordered['ques_ans'].notna()]  # Remove NaN values\ndf2_ordered = df2_ordered[df2_ordered['ques_ans'].str.strip() != '']  # Remove empty strings\ndf2_ordered.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.628342Z","iopub.execute_input":"2024-10-19T03:13:10.628784Z","iopub.status.idle":"2024-10-19T03:13:10.659455Z","shell.execute_reply.started":"2024-10-19T03:13:10.628741Z","shell.execute_reply":"2024-10-19T03:13:10.657937Z"},"trusted":true},"execution_count":187,"outputs":[{"execution_count":187,"output_type":"execute_result","data":{"text/plain":"                                            ques_ans  IsBully\n0  whats your favorite song d  i like too many so...    False\n1                                   3  3  haha jk 33    False\n2        hey angel  you duh sexy  really thanks haha    False\n4                                       meowww  rawr    False\n5  any makeup tips i suck at doing my makeup lol ...    False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ques_ans</th>\n      <th>IsBully</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>whats your favorite song d  i like too many so...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3  3  haha jk 33</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hey angel  you duh sexy  really thanks haha</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>meowww  rawr</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>any makeup tips i suck at doing my makeup lol ...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df2_ordered['ques_ans'].values\ny = df2_ordered['IsBully'].values","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.661267Z","iopub.execute_input":"2024-10-19T03:13:10.661861Z","iopub.status.idle":"2024-10-19T03:13:10.668545Z","shell.execute_reply.started":"2024-10-19T03:13:10.661782Z","shell.execute_reply":"2024-10-19T03:13:10.667268Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\n# Initialize the tokenizer and fit it on the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\n\n# Convert the text to sequences of integers\nsequences = tokenizer.texts_to_sequences(X)\n\n# Pad sequences to ensure uniform input length (e.g., max_len=100)\nmax_len = 50  # Maximum length of sequences\npadded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n\n# Vocabulary size\nvocab_size = len(tokenizer.word_index) + 1  # +1 because the tokenizer index starts at 1\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:10.670086Z","iopub.execute_input":"2024-10-19T03:13:10.670570Z","iopub.status.idle":"2024-10-19T03:13:11.390175Z","shell.execute_reply.started":"2024-10-19T03:13:10.670526Z","shell.execute_reply":"2024-10-19T03:13:11.388541Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"# Stratify ensures that the class proportions are maintained across splits\nX_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n\n# Further split train into train and validation\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:11.392637Z","iopub.execute_input":"2024-10-19T03:13:11.393395Z","iopub.status.idle":"2024-10-19T03:13:11.409523Z","shell.execute_reply.started":"2024-10-19T03:13:11.393294Z","shell.execute_reply":"2024-10-19T03:13:11.408157Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\n# Assuming X_train is your feature matrix and y_train is your target (label)\nundersampler = RandomUnderSampler(random_state=42)\n\n# Perform undersampling\nX_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\nX_val_resampled, y_val_resampled = undersampler.fit_resample(X_val, y_val)\nX_test_resampled, y_test_resampled = undersampler.fit_resample(X_test, y_test)\n\n# Check the new class distribution after undersampling\nprint(\"Original class distribution:\", pd.Series(y_train).value_counts())\nprint(\"Resampled class distribution:\", pd.Series(y_train_resampled).value_counts())\nprint(\"Original validation class distribution:\", pd.Series(y_val).value_counts())\nprint(\"Resampled validation class distribution:\", pd.Series(y_val_resampled).value_counts())\nprint(\"Original test class distribution:\", pd.Series(y_test).value_counts())\nprint(\"Resampled test class distribution:\", pd.Series(y_test_resampled).value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:11.411406Z","iopub.execute_input":"2024-10-19T03:13:11.411958Z","iopub.status.idle":"2024-10-19T03:13:11.439920Z","shell.execute_reply.started":"2024-10-19T03:13:11.411899Z","shell.execute_reply":"2024-10-19T03:13:11.438439Z"},"trusted":true},"execution_count":191,"outputs":[{"name":"stdout","text":"Original class distribution: False    6535\nTrue     1148\nName: count, dtype: int64\nResampled class distribution: False    1148\nTrue     1148\nName: count, dtype: int64\nOriginal validation class distribution: False    2179\nTrue      382\nName: count, dtype: int64\nResampled validation class distribution: False    382\nTrue     382\nName: count, dtype: int64\nOriginal test class distribution: False    2190\nTrue      371\nName: count, dtype: int64\nResampled test class distribution: False    371\nTrue     371\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tokenizing and Feature Engineering","metadata":{}},{"cell_type":"code","source":"def load_glove_embeddings(vocab, glove_file='glove.6B.50d.txt', embedding_dim=50):\n    embeddings_index = {}\n    \n    # Load GloVe embeddings\n    with open(glove_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            values = line.split()\n            word = values[0]\n            vector = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = vector\n    \n    # Create embedding matrix for our vocabulary\n    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n    for word, i in vocab.items():\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n        else:\n            embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n    \n    return embedding_matrix","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:11.441593Z","iopub.execute_input":"2024-10-19T03:13:11.442025Z","iopub.status.idle":"2024-10-19T03:13:11.450908Z","shell.execute_reply.started":"2024-10-19T03:13:11.441983Z","shell.execute_reply":"2024-10-19T03:13:11.449468Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"# Load GloVe embeddings for the tokenizer vocabulary\nembedding_matrix = load_glove_embeddings(tokenizer.word_index, '/kaggle/input/glove-embeddings/glove.6B.50d.txt', 50)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:11.452971Z","iopub.execute_input":"2024-10-19T03:13:11.453429Z","iopub.status.idle":"2024-10-19T03:13:16.905812Z","shell.execute_reply.started":"2024-10-19T03:13:11.453376Z","shell.execute_reply":"2024-10-19T03:13:16.904518Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\n# Assuming X_train, X_test, y_train, y_test are your NumPy arrays or padded sequences\n\n# Convert the data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train_resampled, dtype=torch.long)\ny_train_tensor = torch.tensor(y_train_resampled, dtype=torch.float32)  # Assuming binary classification\n\nX_test_tensor = torch.tensor(X_test_resampled, dtype=torch.long)\ny_test_tensor = torch.tensor(y_test_resampled, dtype=torch.float32)\n\nX_val_tensor = torch.tensor(X_val_resampled, dtype=torch.long)\ny_val_tensor = torch.tensor(y_val_resampled, dtype=torch.float32)\n\n\n# Create TensorDataset (combines inputs and labels)\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\n# Create DataLoader for training and testing sets\nbatch_size = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:16.907761Z","iopub.execute_input":"2024-10-19T03:13:16.908541Z","iopub.status.idle":"2024-10-19T03:13:16.921992Z","shell.execute_reply.started":"2024-10-19T03:13:16.908418Z","shell.execute_reply":"2024-10-19T03:13:16.920450Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"class SentimentRNN(nn.Module):\n    \"\"\"\n    The RNN model that will be used to perform Sentiment analysis.\n    \"\"\"\n\n    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers,embedding_matrix, drop_prob=0.01):\n\n        \"\"\"\n        Initialize the model by setting up the layers.\n        \"\"\"\n        super(SentimentRNN, self).__init__()\n\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        # If GloVe embeddings are provided, use them; otherwise, initialize randomly\n        if embedding_matrix is not None:\n            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n        else:\n            #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n            # Load BERT tokenizer and model\n            self.tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n            self.bert = BertModel.from_pretrained(bert_model_name)\n\n\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n        \n        # dropout layer\n        self.dropout = nn.Dropout(drop_prob)\n        \n        # linear and sigmoid layers\n        self.fc = nn.Linear(hidden_dim, output_size)\n        self.sig = nn.Sigmoid()\n        \n\n    def forward(self, x, hidden):\n        \"\"\"\n        Perform a forward pass of our model on some input and hidden state.\n        \"\"\"\n        batch_size = x.size(0)\n     # Initialize hidden state for the current batch size\n        hidden = self.init_hidden(batch_size)\n        # embeddings and lstm_out\n        x = x.long()\n        embeds = self.embedding(x)\n        lstm_out, hidden = self.lstm(embeds, hidden)\n    \n        # stack up lstm outputs\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        \n        # dropout and fully-connected layer\n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        # sigmoid function\n        sig_out = self.sig(out)\n        \n        # reshape to be batch_size first\n        sig_out = sig_out.view(batch_size, -1)\n        sig_out = sig_out[:, -1] # get last batch of labels\n        \n        # return last sigmoid output and hidden state\n        return sig_out, hidden\n       \n    def init_hidden(self, batch_size):\n        ''' Initializes hidden state '''\n        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n        # initialized to zero, for hidden state and cell state of LSTM\n        weight = next(self.parameters()).data\n        \n        if (train_on_gpu):\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:13:16.923518Z","iopub.execute_input":"2024-10-19T03:13:16.923926Z","iopub.status.idle":"2024-10-19T03:13:16.947762Z","shell.execute_reply.started":"2024-10-19T03:13:16.923886Z","shell.execute_reply":"2024-10-19T03:13:16.946365Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"markdown","source":"## Instantiate the network\n​\nHere, we'll instantiate the network. First up, defining the hyperparameters.\n​\n* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n* `n_layers`: Number of LSTM layers in the network. Typically between 1-3\n​\n> Define the model  hyperparameters.\n​","metadata":{}},{"cell_type":"code","source":"# Instantiate the model w/ hyperparams\noutput_size = 1\nembedding_dim = 50\nhidden_dim = 256\nn_layers = 2\nnum_epochs=6\n# Initialize the model\nmodel = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, embedding_matrix=embedding_matrix)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:15:24.233558Z","iopub.execute_input":"2024-10-19T03:15:24.234120Z","iopub.status.idle":"2024-10-19T03:15:24.253097Z","shell.execute_reply.started":"2024-10-19T03:15:24.234077Z","shell.execute_reply":"2024-10-19T03:15:24.251599Z"},"trusted":true},"execution_count":197,"outputs":[{"name":"stdout","text":"SentimentRNN(\n  (embedding): Embedding(20637, 50)\n  (lstm): LSTM(50, 256, num_layers=2, batch_first=True, dropout=0.01)\n  (dropout): Dropout(p=0.01, inplace=False)\n  (fc): Linear(in_features=256, out_features=1, bias=True)\n  (sig): Sigmoid()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# loss and optimization functions\nlr=0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:15:28.801778Z","iopub.execute_input":"2024-10-19T03:15:28.802233Z","iopub.status.idle":"2024-10-19T03:15:28.809621Z","shell.execute_reply.started":"2024-10-19T03:15:28.802194Z","shell.execute_reply":"2024-10-19T03:15:28.808427Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"# training params\n\ncounter = 0\nprint_every = 100\nclip=5 # gradient clipping\n\n# Train the model (simplified training loop)\nfor epoch in range(num_epochs):\n    model.train()\n    hidden = model.init_hidden(batch_size)\n    \n    for inputs, labels in train_loader:\n        hidden = tuple([each.data for each in hidden])  # Detach hidden states\n        counter += 1\n        # Zero the gradients\n        model.zero_grad()\n        \n        # Forward pass\n        output, hidden = model(inputs, hidden)\n        \n        # Loss and backward pass\n        loss = criterion(output.squeeze(), labels.float())\n        loss.backward()\n        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        # Update weights\n        optimizer.step()\n\n        # loss stats\n        if counter % print_every == 0:\n            # Get validation loss\n            val_h = model.init_hidden(batch_size)\n            val_losses = []\n            model.eval()\n            for inputs, labels in valid_loader:\n\n                # Creating new variables for the hidden state, otherwise\n                # we'd backprop through the entire training history\n                val_h = tuple([each.data for each in val_h])\n\n                if(train_on_gpu):\n                    inputs, labels = inputs.cuda(), labels.cuda()\n\n                output, val_h = model(inputs, val_h)\n                val_loss = criterion(output.squeeze(), labels.float())\n\n                val_losses.append(val_loss.item())\n\n            model.train()\n            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n                  \"Step: {}...\".format(counter),\n                  \"Loss: {:.6f}...\".format(loss.item()),\n                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:15:30.863628Z","iopub.execute_input":"2024-10-19T03:15:30.865224Z","iopub.status.idle":"2024-10-19T03:16:31.852616Z","shell.execute_reply.started":"2024-10-19T03:15:30.865167Z","shell.execute_reply":"2024-10-19T03:16:31.851360Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"Epoch: 2/6... Step: 100... Loss: 0.686425... Val Loss: 0.692658\nEpoch: 3/6... Step: 200... Loss: 0.688479... Val Loss: 0.692179\nEpoch: 5/6... Step: 300... Loss: 0.630702... Val Loss: 0.684213\nEpoch: 6/6... Step: 400... Loss: 0.757247... Val Loss: 0.693443\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get test data loss and accuracy\n\ntest_losses = [] # track loss\nnum_correct = 0\n\n# init hidden state\nh = model.init_hidden(batch_size)\ny_pred = []\ny_true = []\nmodel.eval()\n# iterate over test data\nfor inputs, labels in test_loader:\n\n    # Creating new variables for the hidden state, otherwise\n    # we'd backprop through the entire training history\n    h = tuple([each.data for each in h])\n\n    if(train_on_gpu):\n        inputs, labels = inputs.cuda(), labels.cuda()\n    \n    # get predicted outputs\n    output, h = model(inputs, h)\n   \n    # calculate loss\n    test_loss = criterion(output.squeeze(), labels.float())\n    test_losses.append(test_loss.item())\n    \n    # convert output probabilities to predicted class (0 or 1)\n    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n \n    y_pred.extend(pred.bool())\n    y_true.extend(labels.bool())\n    # compare predictions to true label\n    correct_tensor = pred.eq(labels.float().view_as(pred))\n    \n    \n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n   \n    num_correct += np.sum(correct)\n\n\n# -- stats! -- ##\n# avg test loss\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n\n# accuracy over all test data\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}\".format(test_acc))\n\n# Generate classification report\nreport = classification_report(y_true, y_pred, target_names=['False', 'True'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-19T03:16:31.855594Z","iopub.execute_input":"2024-10-19T03:16:31.856258Z","iopub.status.idle":"2024-10-19T03:16:33.254500Z","shell.execute_reply.started":"2024-10-19T03:16:31.856199Z","shell.execute_reply":"2024-10-19T03:16:33.253087Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"Test loss: 0.691\nTest accuracy: 0.511\n              precision    recall  f1-score   support\n\n       False       0.68      0.04      0.08       371\n        True       0.51      0.98      0.67       371\n\n    accuracy                           0.51       742\n   macro avg       0.59      0.51      0.37       742\nweighted avg       0.59      0.51      0.37       742\n\n","output_type":"stream"}]}]}